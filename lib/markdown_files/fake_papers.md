---
title: "Unpopular opinion: Bring back serious consequences to fake papers and fake reviews."
date: "2025-11-14"
author: "Rao"
---
Unpopular opinion: Bring back serious consequences to fake papers and fake reviews. #SundayHarangue (Friday version)

We keep hearing some crazy stories about both papers (e.g. the AAAI experiment where they apparently unearthed multiple LLM-generated versions of the same paper submitted to the conference!) and reviews (e.g. the [@iclr_conf](https://x.com/iclr_conf) tweets about reviews that are fully or partly LLM-generated--with reviewers not even bothering to remove tell tale signs of LLM use).

I think one reason for this sorry state of affairs in the AI/ML conferences is the **safety of anonymity in numbers**.

There was a time when writing a single fake review, or god forbid fake papers would have meant the end of the research career of the people involved. 

This is simply no longer the case--thanks both to author privacy/double-blindness rules, and due to inter-reviewer anonymity. 

The net effect of these is that there is basically less than "slap on the wrist" consequences for bad behavior.. (paradoxical given all the extra effort on "ethics reviews" etc.).

There have to be serious public consequences for unethical behavior.  

Unless the incentive system changes, there is little reason to believe that the current state of affairs will change.. 

One related idea is to stop **inter-reviewer anonymity**--which is a huge reason why people don't mind posting silly LLM reviews.

See this tweet for more details:
https://x.com/rao2z/status/1771272256498594218