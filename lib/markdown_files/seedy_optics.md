---
title: "On the seedy optics of 'Building an AGI Moat by Corralling Benchmark Creators'"
date: "2025-01-19"
author: "Rao"
---

#SundayHarangue

One of the big reasons for the increased volume of "AGI Tomorrow" hype has been o3's performance on the "frontier math" benchmark--something that other models basically had no handle on. 

We are now being told ðŸ‘‡that this benchmark data may have been exclusively available to OpenAI since before o1--and that the benchmark creators were not allowed to disclose this *until after o3 *.

That o3 does well on frontier math held-out set is impressive, no doubt, but the mental picture of "o1/o3 were just being trained on simple math, and they bootstrapped themselves to frontier math"--that the AGI tomorrow crowd seem to have--that OpenAI while not explicitly claiming, certainly didn't directly contradict--is shattered by this.

I do think o1/o3 are impressive technical achievements (see [this tweet](https://x.com/rao2z/status/1834354533931385203))

Doing well on hard benchmarks that you had prior access to is still impressive--but doesn't quite scream "AGI Tomorrow."

We all know that data contamination is an issue with LLMs and LRMs. We also know that reasoning claims need more careful vetting than "we didn't see that specific problem instance during training" 

see "In vs. Out of Distribution analyses are not that useful for understanding LLM reasoning capabilities" 

https://x.com/rao2z/status/1827778006972248123

At the very least, this episode further argues for increased vigilance/skepticism on the part of AI research community in how they parse the benchmark claims put out commercial entities.

https://x.com/rao2z/status/1881079432624168999